Data Catalogue and Processing K100 R53
======================================

Ok, time to get back into the data processing for the K100.  I came some distance in this when
working at Fermilab last summer, but now I have to close the loop and make the processing
automated.  Just to go over all the steps we need I'll list here:

1. copy raw data from `Vuk-01.spa.umn.edu` to `/data/chocula/`
2. change data over to IZIP format?  -- this really hurts us, can we get rid of it?
3. copy the raw data to offsite locations like `nero`/`nerva`/`galba.stanford.edu`
4. make appropriate directory structures on `/data/chocula/`
5. process the data in one of the locations
6. merge data from the above processing
7. sync with other locations


So, I've been fishing around for a while to find where all my code related to this is, here is a
list.

* on `vegemite.spa.umn.edu` at `umn_work/cdms_analysis/cpp/s34/` we have scripts for copying UMN
    data and making directory structures.  This is in my CVS code_repository. 
* on `cdmsmicro.fnal.gov` at `/localhome/cdms/user_dir/villaa/R46_proc_cvs` I have the processing
    scripts and the versions of cdmsbats I've used for the most recent processing of R46 data.
    Oddly it says that this should be in my code repository at `umn_work/R46_proc`, but I can't
    find it there -- actually update, it's there but not checked out on `vegemite`. 
